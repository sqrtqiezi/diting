# 功能规范：微信消息数据湖存储

**功能分支**: `006-wechat-message-storage`
**创建日期**: 2026-01-23
**状态**: 草稿
**输入**: 用户描述："设计并实现基于 JSON + Parquet 格式的微信消息数据湖存储方案，支持从 webhook 日志持久化消息，无需数据库服务器"

## 澄清记录

### 会话 2026-01-23

- Q: 当 Webhook 收到消息时，如何写入临时 JSON 文件？ → A: 追加到当日 JSONL 文件（如 `2026-01-23.jsonl`，每行一条消息）
- Q: 每日将 JSONL 文件转储为 Parquet 的定时任务应该在什么时间运行？ → A: 凌晨 02:00
- Q: 当 JSONL 文件成功转储为 Parquet 后，应该如何处理原始 JSONL 文件？ → A: 保留 7 天后删除
- Q: 应该选择哪一个作为默认 Parquet 压缩算法？ → A: Snappy
- Q: 如何处理现有的历史数据（wechat_webhook.log 和 parsed_messages_*.json）？ → A: 忽略历史数据，仅从新架构启用后开始存储

## 用户场景与测试 *(必填)*

### 用户故事 1 - 持久化消息到结构化存储 (优先级: P1)

作为数据分析师，我需要将原始 webhook 日志转换为结构化存储文件，以便高效查询和分析微信消息历史，而无需将大量 JSON 文件加载到内存中。

**优先级原因**: 这是所有数据分析的基础。如果没有结构化存储，当前 342MB+ 的日志文件难以查询和分析。这使得所有下游用例成为可能。

**独立测试**: 可以通过在现有 webhook 日志上运行存储管道，验证 Parquet 文件是否以正确的 schema 创建且所有消息都被保留来完整测试。

**验收场景**:

1. **假设** webhook 日志包含 23,210 条消息，**当** 存储管道运行时，**那么** 所有消息都被持久化到 Parquet 文件且无数据丢失
2. **假设** 消息有两种类型（消息内容 98%，联系人同步 1.6%），**当** 存储管道处理它们时，**那么** 每种类型都存储在具有适当 schema 的独立 Parquet 文件中
3. **假设** webhook 日志中有新消息到达，**当** 增量存储运行时，**那么** 仅处理新消息并追加到存储
4. **假设** 存储的 Parquet 文件存在，**当** 按日期范围查询时，**那么** 典型查询（1 天数据）在 1 秒内返回结果

---

### 用户故事 2 - 高效查询历史消息 (优先级: P2)

作为数据分析师，我需要按各种条件（日期、发送者、聊天室、消息类型）查询历史消息，以便从对话历史中提取洞察并构建知识图谱。

**优先级原因**: 一旦数据被存储，高效查询能力对于分析至关重要。这使得知识图谱功能（Feature 004）和其他分析用例成为可能。

**独立测试**: 可以通过对存储数据运行预定义查询并测量查询性能和结果准确性来测试。

**验收场景**:

1. **假设** 消息以 Parquet 格式存储，**当** 查询特定日期的消息时，**那么** 返回结果而无需将整个数据集加载到内存
2. **假设** 来自多个聊天室的消息，**当** 按聊天室 ID 过滤时，**那么** 仅返回该聊天室的消息
3. **假设** 不同类型的消息（文本、图片、文章），**当** 按 msg_type 过滤时，**那么** 仅返回匹配的消息
4. **假设** 大日期范围查询（1 个月），**当** 查询执行时，**那么** 结果在 5 秒内返回

---

### 用户故事 3 - 维护数据质量和完整性 (优先级: P2)

作为系统管理员，我需要存储系统验证数据质量并处理 schema 演化，以便数据随时间保持一致和可用。

**优先级原因**: 数据质量问题会破坏分析结果。Schema 演化支持确保系统能够适应微信 API 变化而不破坏现有数据。

**独立测试**: 可以通过引入格式错误的消息和 schema 变更，然后验证系统是否优雅地处理它们来测试。

**验收场景**:

1. **假设** webhook 日志中有格式错误的消息，**当** 存储管道处理它时，**那么** 错误被记录且其他消息继续处理
2. **假设** 微信向消息 schema 添加新字段，**当** 存储管道遇到新字段时，**那么** 它们被保留在 Parquet 文件中而不破坏现有查询
3. **假设** webhook 日志中有重复消息，**当** 存储管道运行时，**那么** 基于 msg_id 检测并跳过重复项
4. **假设** 存储的数据，**当** 验证运行时，**那么** 数据完整性检查确认所有必需字段存在且类型正确

---

### 用户故事 4 - 归档和管理存储增长 (优先级: P3)

作为系统管理员，我需要通过分区和归档管理存储增长，以便随着数据量增长系统保持高性能和成本效益。

**优先级原因**: 虽然对 MVP 不是关键，但这确保了长期可持续性。没有它，查询性能会下降，存储成本会无限增长。

**独立测试**: 可以通过模拟数月数据并验证分区正常工作且旧数据可以归档来测试。

**验收场景**:

1. **假设** 跨越多个月的消息，**当** 存储管道运行时，**那么** 数据按年/月分区以实现高效查询
2. **假设** 超过保留期的数据，**当** 归档流程运行时，**那么** 旧数据根据策略移至冷存储或删除
3. **假设** 分区数据，**当** 查询最近数据（最近 7 天）时，**那么** 仅扫描相关分区
4. **假设** 存储使用指标，**当** 检查监控仪表板时，**那么** 当前存储大小和增长率可见

---

### 边界情况

- 当 webhook 日志文件损坏或包含无效 JSON 时会发生什么？
  - 系统应跳过损坏的条目，记录错误，并继续处理有效条目
- 当由于磁盘空间不足导致 Parquet 文件写入失败时会发生什么？
  - 系统应检测错误，记录它，并使用指数退避重试
- 当消息 schema 发生重大变化（破坏性变更）时会发生什么？
  - 系统应检测 schema 不兼容并创建新的版本化 Parquet 文件
- 当查询跨越多个 Parquet 文件的数据时会发生什么？
  - 查询引擎应自动合并来自多个文件的结果
- 当两个进程尝试同时写入存储时会发生什么？
  - 文件锁定或原子写入应防止数据损坏
- 当源字段类型改变时会发生什么（例如，`source` 字段有时是 int，有时是 string）？
  - Schema 应使用联合类型或转换为字符串以处理两种情况

## 需求 *(必填)*

### 功能需求

- **FR-001**: Webhook 接收器必须在收到消息时立即将其追加到当日 JSONL 文件（格式：`data/messages/raw/YYYY-MM-DD.jsonl`，每行一条 JSON 消息）
- **FR-002**: 系统必须提供每日定时任务（凌晨 02:00 运行），将前一天的 JSONL 文件转储为 Parquet 格式
- **FR-003**: 系统必须在成功转储后保留原始 JSONL 文件 7 天，然后自动删除以释放磁盘空间
- **FR-004**: 系统必须根据字段数量区分消息内容类型（11 个字段）和联系人同步类型（46-55 个字段）
- **FR-005**: 系统必须将消息内容和联系人同步数据存储在具有适当 schema 的独立 Parquet 文件中
- **FR-006**: 系统必须保留源数据的所有字段，包括嵌套结构（XML 字符串、字典）
- **FR-007**: 系统必须按日期（年/月/日）分区 Parquet 文件以实现高效查询
- **FR-008**: 系统必须支持增量处理以避免重新处理整个日志文件
- **FR-009**: 系统必须基于 `msg_id` 字段检测并跳过重复消息
- **FR-010**: 系统必须验证数据类型并处理类型不一致（例如，`source` 字段为 int 或 string）
- **FR-011**: 系统必须记录所有处理错误（格式错误的 JSON、schema 违规）而不停止管道
- **FR-012**: 系统必须提供查询接口以读取 Parquet 文件，支持按日期、发送者、聊天室、消息类型过滤
- **FR-013**: 系统必须维护关于存储数据的元数据（记录数、日期范围、文件位置）
- **FR-014**: 系统必须通过在 Parquet 文件中保留未知字段来支持 schema 演化
- **FR-015**: 系统必须使用 Snappy 压缩算法来压缩 Parquet 文件以提高存储效率
- **FR-016**: 系统必须提供用于存储操作的 CLI 命令（摄取、查询、验证、归档）
- **FR-017**: 系统必须处理敏感数据字段（mobile、customInfo.detail），具有可选的脱敏能力

### 关键实体

- **消息内容记录**: 表示具有 11 个核心字段的微信消息
  - 属性: from_username, to_username, chatroom, chatroom_sender, msg_id, msg_type, create_time, is_chatroom_msg, content (XML), desc, source (XML/int)
  - 关系: 属于聊天室，由用户发送，具有消息类型
  - 分区: 按 create_time（年/月/日）

- **联系人同步记录**: 表示具有 46-55 个字段的联系人/聊天室同步数据
  - 属性: 基本信息（alias, username, encryptUserName）、状态标志（contactType, deleteFlag, verifyFlag）、联系人设置、图像 URL、地理数据、联系人备注、群组信息、社交数据、企业扩展
  - 关系: 表示联系人或聊天室实体
  - 分区: 按同步时间戳（年/月/日）

- **存储分区**: 表示基于时间的数据分区
  - 属性: partition_key（年/月/日）、record_count、file_path、size_bytes、created_at、last_updated_at
  - 关系: 包含多个消息或联系人记录

- **处理检查点**: 跟踪增量处理进度
  - 属性: last_processed_offset、last_processed_timestamp、processed_record_count、checkpoint_time
  - 关系: 引用源日志文件

## 成功标准 *(必填)*

### 可测量结果

- **SC-001**: 存储管道在标准硬件上在 5 分钟内处理 23,210 条现有消息
- **SC-002**: 查询性能在 1 秒内返回单日查询结果
- **SC-003**: 存储效率相比原始 JSON 日志实现至少 50% 的压缩率
- **SC-004**: 数据完整性验证确认 100% 的消息被保留且无数据丢失
- **SC-005**: 增量处理在 webhook 日志更新后 1 分钟内将新消息添加到存储
- **SC-006**: 系统处理 schema 演化而无需手动干预或数据迁移
- **SC-007**: 查询接口支持按日期、发送者、聊天室和消息类型过滤并返回正确结果
- **SC-008**: 存储系统运行无需外部数据库服务器或守护进程

## 假设 *(可选)*

- Webhook 日志是仅追加的，消息在写入后不会被修改
- 消息 ID（`msg_id`）是唯一的，可用于去重
- 系统有足够的磁盘空间存储 Parquet 文件（估计为原始日志大小的 50%）
- Python 环境可以访问 PyArrow/Pandas 库进行 Parquet 操作
- 文件系统支持原子写入或文件锁定以保护并发访问
- 数据保留策略将在稍后定义（默认：保留所有数据）
- 查询工作负载主要是分析性的（批量查询）而非事务性的（点查找）
- Parquet 文件将存储在与应用程序相同的服务器上

## 不在范围内 *(可选)*

- 历史数据迁移（现有的 `wechat_webhook.log` 和 `parsed_messages_*.json` 文件不会被转换，新架构仅处理启用后的新数据）
- 实时流式摄取（MVP 仅批处理）
- 跨多个服务器的分布式存储
- SQL 查询接口（MVP 仅 Python API）
- 数据可视化仪表板
- 自动备份和灾难恢复
- `content` 和 `source` 字段的 XML 解析（存储为原始字符串）
- 与外部数据湖（S3、HDFS 等）的集成
- 查询的用户身份验证和访问控制
- 静态数据加密（文件系统加密已足够）

## 依赖 *(可选)*

- **Feature 003（微信通知 Webhook）**: 提供需要存储的源 webhook 日志
- **Python 库**: PyArrow（Parquet I/O）、Pandas（数据操作）、Pydantic（schema 验证）
- **文件系统**: 需要具有足够空间和写入权限的本地文件系统
- **现有数据**: `data/wechat_webhook.log` 和 `data/parsed_messages_*.json` 文件

## 参考 *(可选)*

- `docs/wechat-message-schema.md`: 微信 webhook 消息的详细 schema 文档
- Apache Parquet 格式规范: https://parquet.apache.org/docs/
- PyArrow 文档: https://arrow.apache.org/docs/python/
- 数据湖架构模式: https://www.databricks.com/glossary/data-lake
